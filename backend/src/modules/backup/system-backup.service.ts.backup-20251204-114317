import * as fs from 'fs/promises';
import * as path from 'path';
import * as crypto from 'crypto';
import { prisma } from '../../services/prisma.service';
import { SystemBackupType, BackupStatus } from '@prisma/client';
import {
  safePgDump,
  safeTar,
  safeExec,
  validatePath,
  validatePgIdentifier,
} from '../../utils/shell-sanitizer';

const BACKUP_DIR = '/var/backups/vps-panel';
const VPS_PANEL_DIR = '/vps-panel-source';  // Mounted from /root/vps-panel on host
const PROJECTS_DIR = '/var/www/projects';

interface BackupResult {
  success: boolean;
  backupId?: string;
  filename?: string;
  filepath?: string;
  size?: number;
  error?: string;
}

export class SystemBackupService {
  constructor() {
    this.ensureBackupDir();
  }

  private async ensureBackupDir() {
    try {
      await fs.mkdir(BACKUP_DIR, { recursive: true });
    } catch (error) {
      console.error('Error creating backup directory:', error);
    }
  }

  private formatBytes(bytes: number): string {
    if (bytes === 0) return '0 B';
    const k = 1024;
    const sizes = ['B', 'KB', 'MB', 'GB', 'TB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(2)) + ' ' + sizes[i];
  }

  private generateFilename(type: SystemBackupType): string {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const prefix = type === 'SYSTEM_TEMPLATE' ? 'system-template' : 'full-backup';
    return `${prefix}-${timestamp}.tar.gz`;
  }

  private async calculateChecksum(filepath: string): Promise<string> {
    const fileBuffer = await fs.readFile(filepath);
    const hashSum = crypto.createHash('sha256');
    hashSum.update(fileBuffer);
    return hashSum.digest('hex');
  }

  /**
   * Create System Template Backup
   * Include solo il sistema VPS Panel senza progetti
   */
  async createSystemTemplateBackup(notes?: string): Promise<BackupResult> {
    const filename = this.generateFilename('SYSTEM_TEMPLATE');
    const filepath = path.join(BACKUP_DIR, filename);
    const tempDir = path.join(BACKUP_DIR, `temp-${Date.now()}`);

    // Create backup record
    const backup = await prisma.systemBackup.create({
      data: {
        type: 'SYSTEM_TEMPLATE',
        filename,
        filepath,
        size: BigInt(0),
        status: 'PROCESSING',
        notes,
        includedComponents: [
          'vps-panel-source',
          'docker-compose',
          'traefik-config',
          'env-files',
          'database-schema',
          'system-settings',
          'users',
        ],
        excludedPaths: [
          'node_modules',
          '.next',
          'dist',
          '/var/www/projects',
          'traefik/dynamic/projects',
        ],
      },
    });

    try {
      // Create temp directory
      await fs.mkdir(tempDir, { recursive: true });

      // 1. Export database schema + essential tables
      console.log('Exporting database schema...');
      const schemaFile = path.join(tempDir, 'database-schema.sql');
      const dataFile = path.join(tempDir, 'database-essential.sql');

      // Use pg_dump via network connection (postgres is accessible via hostname 'postgres')
      const pgUser = process.env.POSTGRES_USER || 'vpsadmin';
      const pgDb = process.env.POSTGRES_DB || 'vps_panel';
      const pgPassword = process.env.POSTGRES_PASSWORD || '';
      const pgHost = 'postgres';

      // Validate PostgreSQL identifiers
      if (!validatePgIdentifier(pgUser)) {
        throw new Error(`Invalid PostgreSQL username: ${pgUser}`);
      }
      if (!validatePgIdentifier(pgDb)) {
        throw new Error(`Invalid PostgreSQL database name: ${pgDb}`);
      }

      // Use safe pg_dump wrapper
      await safePgDump({
        host: pgHost,
        user: pgUser,
        database: pgDb,
        password: pgPassword,
        outputFile: schemaFile,
        schemaOnly: true,
      });

      // Export only essential data (users, system_settings)
      await safePgDump({
        host: pgHost,
        user: pgUser,
        database: pgDb,
        password: pgPassword,
        outputFile: dataFile,
        dataOnly: true,
        tables: ['users', 'system_settings'],
      });

      // 2. Copy VPS Panel source (excluding node_modules, .next, dist)
      console.log('Copying VPS Panel source...');
      const sourceDir = path.join(tempDir, 'vps-panel');
      await fs.mkdir(sourceDir, { recursive: true });

      // Use safe tar wrapper for creating archives
      try {
        await safeExec('tar', [
          'czf', `${sourceDir}/backend-src.tar.gz`,
          '-C', `${VPS_PANEL_DIR}/backend/src`,
          '.'
        ], { timeout: 120000 });
      } catch (e) {
        console.log('Backend source archive skipped');
      }

      try {
        await safeExec('tar', [
          'czf', `${sourceDir}/frontend-src.tar.gz`,
          '-C', `${VPS_PANEL_DIR}/frontend/src`,
          '.'
        ], { timeout: 120000 });
      } catch (e) {
        console.log('Frontend source archive skipped');
      }

      // Copy config files
      const configFiles = [
        'docker-compose.yml',
        'docker-compose.override.yml',
        '.env',
        'backend/package.json',
        'backend/tsconfig.json',
        'backend/prisma/schema.prisma',
        'frontend/package.json',
        'frontend/tsconfig.json',
        'frontend/next.config.mjs',
        'frontend/tailwind.config.ts',
      ];

      for (const file of configFiles) {
        const srcPath = path.join(VPS_PANEL_DIR, file);
        const destPath = path.join(sourceDir, file);
        try {
          await fs.mkdir(path.dirname(destPath), { recursive: true });
          await fs.copyFile(srcPath, destPath);
        } catch (e) {
          // File might not exist
        }
      }

      // 3. Copy Traefik config (excluding project-specific configs)
      console.log('Copying Traefik config...');
      const traefikDir = path.join(tempDir, 'traefik');
      await fs.mkdir(traefikDir, { recursive: true });

      // Use safe file copy with fs
      try {
        await fs.copyFile(`${VPS_PANEL_DIR}/traefik/traefik.yml`, `${traefikDir}/traefik.yml`);
      } catch (e) { /* ignore if not exists */ }
      try {
        await fs.copyFile(`${VPS_PANEL_DIR}/traefik/dynamic/middlewares.yml`, `${traefikDir}/middlewares.yml`);
      } catch (e) { /* ignore if not exists */ }
      try {
        await fs.copyFile(`${VPS_PANEL_DIR}/traefik/dynamic/tls.yml`, `${traefikDir}/tls.yml`);
      } catch (e) { /* ignore if not exists */ }

      // 4. Copy Docker configs
      console.log('Copying Docker configs...');
      const dockerDir = path.join(tempDir, 'docker');
      await fs.mkdir(dockerDir, { recursive: true });
      try {
        await safeExec('cp', ['-r', `${VPS_PANEL_DIR}/docker/.`, dockerDir], { timeout: 30000 });
      } catch (e) {
        console.log('Docker configs not found');
      }

      // 5. Create restore script
      const restoreScript = `#!/bin/bash
# VPS Panel System Template Restore Script
# Created: ${new Date().toISOString()}

echo "=== VPS Panel System Restore ==="
echo "This will set up the VPS Panel on a new server"
echo ""

# Check if running as root
if [ "$EUID" -ne 0 ]; then
  echo "Please run as root"
  exit 1
fi

# Create directories
mkdir -p /root/vps-panel
mkdir -p /var/www/projects
mkdir -p /var/backups/vps-panel

# Extract source files
echo "Extracting source files..."
tar xzf vps-panel/backend-src.tar.gz -C /root/vps-panel/backend/src/
tar xzf vps-panel/frontend-src.tar.gz -C /root/vps-panel/frontend/src/

# Copy config files
echo "Copying config files..."
cp -r vps-panel/* /root/vps-panel/

# Copy Traefik config
echo "Setting up Traefik..."
mkdir -p /root/vps-panel/traefik/dynamic
cp traefik/* /root/vps-panel/traefik/
cp traefik/middlewares.yml /root/vps-panel/traefik/dynamic/ 2>/dev/null || true
cp traefik/tls.yml /root/vps-panel/traefik/dynamic/ 2>/dev/null || true

# Copy Docker configs
cp -r docker/* /root/vps-panel/docker/ 2>/dev/null || true

echo ""
echo "=== Next Steps ==="
echo "1. Edit /root/vps-panel/.env with your settings"
echo "2. Run: cd /root/vps-panel && docker compose up -d"
echo "3. Import database: cat database-schema.sql database-essential.sql | docker exec -i vps-panel-postgres psql -U vpsadmin -d vps_panel"
echo ""
echo "Restore complete!"
`;

      await fs.writeFile(path.join(tempDir, 'restore.sh'), restoreScript);
      await fs.chmod(path.join(tempDir, 'restore.sh'), 0o755);

      // 6. Create final archive
      console.log('Creating backup archive...');
      await safeExec('tar', ['czf', filepath, '-C', tempDir, '.'], { timeout: 300000 });

      // Get file size and checksum
      const stats = await fs.stat(filepath);
      const checksum = await this.calculateChecksum(filepath);

      // Cleanup temp directory
      await fs.rm(tempDir, { recursive: true, force: true }).catch((err) => {
        console.error('Warning: Failed to cleanup temp directory:', err.message);
      });

      // Update backup record
      await prisma.systemBackup.update({
        where: { id: backup.id },
        data: {
          status: 'UPLOADED',
          size: BigInt(stats.size),
          checksum,
          completedAt: new Date(),
        },
      });

      console.log(`System template backup created: ${filename} (${this.formatBytes(stats.size)})`);

      return {
        success: true,
        backupId: backup.id,
        filename,
        filepath,
        size: stats.size,
      };
    } catch (error: any) {
      console.error('Error creating system backup:', error);

      // Cleanup on error - use Promise.allSettled to ensure all cleanup attempts run
      await Promise.allSettled([
        fs.rm(tempDir, { recursive: true, force: true }),
        fs.rm(filepath, { force: true }),
      ]).then((results) => {
        results.forEach((result, index) => {
          if (result.status === 'rejected') {
            console.error(`Warning: Cleanup failed for ${index === 0 ? 'temp directory' : 'backup file'}:`, result.reason?.message);
          }
        });
      });

      await prisma.systemBackup.update({
        where: { id: backup.id },
        data: {
          status: 'FAILED',
          errorMessage: error.message,
        },
      });

      return {
        success: false,
        backupId: backup.id,
        error: error.message,
      };
    }
  }

  /**
   * Create a backup record (for async processing)
   */
  async createBackupRecord(type: SystemBackupType, notes?: string) {
    const filename = this.generateFilename(type);
    const filepath = path.join(BACKUP_DIR, filename);

    const backup = await prisma.systemBackup.create({
      data: {
        type,
        filename,
        filepath,
        size: BigInt(0),
        status: 'PROCESSING',
        notes,
        includedComponents:
          type === 'FULL_DISASTER'
            ? [
                'vps-panel-source',
                'docker-compose',
                'traefik-config',
                'traefik-dynamic',
                'traefik-acme',
                'env-files',
                'database-full',
                'redis-dump',
                'projects',
                'docker-volumes',
              ]
            : [
                'vps-panel-source',
                'docker-compose',
                'traefik-config',
                'env-files',
                'database-schema',
                'system-settings',
                'users',
              ],
        excludedPaths:
          type === 'FULL_DISASTER'
            ? ['node_modules', '.next', 'dist']
            : [
                'node_modules',
                '.next',
                'dist',
                '/var/www/projects',
                'traefik/dynamic/projects',
              ],
      },
    });

    return { id: backup.id, filename, filepath };
  }

  /**
   * Process a full backup (called asynchronously)
   */
  async processFullBackup(backupId: string): Promise<BackupResult> {
    const backup = await prisma.systemBackup.findUnique({
      where: { id: backupId },
    });

    if (!backup) {
      return { success: false, error: 'Backup record not found' };
    }

    const { filename, filepath } = backup;
    const tempDir = path.join(BACKUP_DIR, `temp-full-${Date.now()}`);

    try {
      // Create temp directory
      await fs.mkdir(tempDir, { recursive: true });

      // 1. Full database dump
      console.log('Exporting full database...');
      const dbFile = path.join(tempDir, 'database-full.sql');
      const pgUser = process.env.POSTGRES_USER || 'vpsadmin';
      const pgDb = process.env.POSTGRES_DB || 'vps_panel';
      const pgPassword = process.env.POSTGRES_PASSWORD || '';
      const pgHost = 'postgres';

      // Validate and use safe pg_dump
      if (!validatePgIdentifier(pgUser)) {
        throw new Error(`Invalid PostgreSQL username: ${pgUser}`);
      }
      if (!validatePgIdentifier(pgDb)) {
        throw new Error(`Invalid PostgreSQL database name: ${pgDb}`);
      }

      await safePgDump({
        host: pgHost,
        user: pgUser,
        database: pgDb,
        password: pgPassword,
        outputFile: dbFile,
      });

      // 2. Redis dump - skip for now as it requires docker access
      console.log('Redis dump skipped (requires external access)');
      // Redis data is persisted in the volume, will be included via volume backup

      // 3. Copy VPS Panel source (mounted at /vps-panel-source:ro in container)
      console.log('Copying VPS Panel source...');
      await safeExec('tar', [
        'czf', `${tempDir}/vps-panel-source.tar.gz`,
        '--exclude=node_modules',
        '--exclude=.next',
        '--exclude=dist',
        '-C', '/vps-panel-source',
        '.'
      ], { timeout: 300000 });

      // 4. Copy all Traefik configs (including project-specific)
      console.log('Copying Traefik configs...');
      await safeExec('tar', [
        'czf', `${tempDir}/traefik-config.tar.gz`,
        '-C', VPS_PANEL_DIR,
        'traefik'
      ], { timeout: 60000 });

      // 5. Export ACME certificates (mounted at /traefik-acme)
      console.log('Exporting SSL certificates...');
      try {
        const acmePath = '/traefik-acme/acme.json';
        const acmeExists = await fs.stat(acmePath).then(() => true).catch(() => false);
        if (acmeExists) {
          await fs.copyFile(acmePath, path.join(tempDir, 'acme.json'));
        }
      } catch (e) {
        console.log('ACME certificates not found');
      }

      // 6. Copy projects directory
      console.log('Copying projects...');
      try {
        const projectsExist = await fs
          .stat(PROJECTS_DIR)
          .then(() => true)
          .catch(() => false);
        if (projectsExist) {
          await safeExec('tar', [
            'czf', `${tempDir}/projects.tar.gz`,
            '-C', '/var/www',
            'projects'
          ], { timeout: 600000 });
        }
      } catch (e) {
        console.log('Projects directory empty or not found');
      }

      // 7. Export Docker volumes info (actual volume backup requires host access)
      // Docker CLI is not available in the container, so we skip volume export
      // Projects data is already included via /var/www/projects
      console.log('Docker volumes backup skipped (requires host access)');
      console.log('Note: Project files are included via projects.tar.gz');

      // 8. Create restore script
      const restoreScript = `#!/bin/bash
# VPS Panel Full Disaster Recovery Restore Script
# Created: ${new Date().toISOString()}

echo "=== VPS Panel Full Restore ==="
echo "WARNING: This will overwrite existing data!"
echo ""

read -p "Are you sure? (yes/no): " confirm
if [ "$confirm" != "yes" ]; then
  echo "Cancelled"
  exit 1
fi

# Check if running as root
if [ "$EUID" -ne 0 ]; then
  echo "Please run as root"
  exit 1
fi

# Stop existing containers
echo "Stopping existing containers..."
cd /root/vps-panel && docker compose down 2>/dev/null || true

# Restore VPS Panel source
echo "Restoring VPS Panel source..."
tar xzf vps-panel-source.tar.gz -C /root/

# Restore Traefik config
echo "Restoring Traefik config..."
tar xzf traefik-config.tar.gz -C /root/vps-panel/

# Restore projects
echo "Restoring projects..."
mkdir -p /var/www
tar xzf projects.tar.gz -C /var/www/ 2>/dev/null || echo "No projects to restore"

# Start containers
echo "Starting containers..."
cd /root/vps-panel && docker compose up -d

# Wait for database
echo "Waiting for database..."
sleep 10

# Restore database
echo "Restoring database..."
cat database-full.sql | docker exec -i vps-panel-postgres psql -U vpsadmin -d vps_panel

# Restore Redis
if [ -f "redis-dump.rdb" ]; then
  echo "Restoring Redis..."
  docker cp redis-dump.rdb vps-panel-redis:/data/dump.rdb
  docker restart vps-panel-redis
fi

# Restore ACME certificates
if [ -f "acme.json" ]; then
  echo "Restoring SSL certificates..."
  docker cp acme.json vps-panel-traefik:/acme.json
  docker restart vps-panel-traefik
fi

# Restore Docker volumes
echo "Restoring Docker volumes..."
for vol_file in volumes/*.tar.gz; do
  if [ -f "$vol_file" ]; then
    vol_name=$(basename "$vol_file" .tar.gz)
    docker volume create "$vol_name" 2>/dev/null || true
    docker run --rm -v "$vol_name":/data -v "$(pwd)/volumes":/backup alpine tar xzf /backup/$(basename "$vol_file") -C / 2>/dev/null || true
  fi
done

echo ""
echo "=== Restore Complete ==="
echo "Please restart all project containers manually if needed"
`;

      await fs.writeFile(path.join(tempDir, 'restore.sh'), restoreScript);
      await fs.chmod(path.join(tempDir, 'restore.sh'), 0o755);

      // 9. Create final archive
      console.log('Creating full backup archive...');
      await safeExec('tar', ['czf', filepath, '-C', tempDir, '.'], { timeout: 600000 });

      // Get file size and checksum
      const stats = await fs.stat(filepath);
      const checksum = await this.calculateChecksum(filepath);

      // Cleanup temp directory
      await fs.rm(tempDir, { recursive: true, force: true }).catch((err) => {
        console.error('Warning: Failed to cleanup temp directory:', err.message);
      });

      // Update backup record
      await prisma.systemBackup.update({
        where: { id: backupId },
        data: {
          status: 'UPLOADED',
          size: BigInt(stats.size),
          checksum,
          completedAt: new Date(),
        },
      });

      console.log(`Full backup created: ${filename} (${this.formatBytes(stats.size)})`);

      return {
        success: true,
        backupId,
        filename,
        filepath,
        size: stats.size,
      };
    } catch (error: any) {
      console.error('Error creating full backup:', error);

      // Cleanup on error - use Promise.allSettled to ensure all cleanup attempts run
      await Promise.allSettled([
        fs.rm(tempDir, { recursive: true, force: true }),
        fs.rm(filepath, { force: true }),
      ]).then((results) => {
        results.forEach((result, index) => {
          if (result.status === 'rejected') {
            console.error(`Warning: Cleanup failed for ${index === 0 ? 'temp directory' : 'backup file'}:`, result.reason?.message);
          }
        });
      });

      await prisma.systemBackup.update({
        where: { id: backupId },
        data: {
          status: 'FAILED',
          errorMessage: error.message,
        },
      });

      return {
        success: false,
        backupId,
        error: error.message,
      };
    }
  }

  /**
   * Create Full Disaster Recovery Backup (legacy sync method)
   * Include tutto: sistema, progetti, database, volumi
   */
  async createFullBackup(notes?: string): Promise<BackupResult> {
    const record = await this.createBackupRecord('FULL_DISASTER', notes);
    return this.processFullBackup(record.id);
  }

  /**
   * Get the most recent backup that is still processing
   * Used to return the ID immediately when starting async backups
   */
  async getLatestProcessingBackupId(): Promise<string | null> {
    const backup = await prisma.systemBackup.findFirst({
      where: { status: 'PROCESSING' },
      orderBy: { createdAt: 'desc' },
      select: { id: true },
    });
    return backup?.id || null;
  }

  /**
   * List all system backups
   */
  async listBackups(type?: SystemBackupType) {
    const where = type ? { type } : {};

    const backups = await prisma.systemBackup.findMany({
      where,
      orderBy: { createdAt: 'desc' },
      take: 50,
    });

    return backups.map((b) => ({
      ...b,
      size: Number(b.size),
      sizeFormatted: this.formatBytes(Number(b.size)),
    }));
  }

  /**
   * Get backup by ID
   */
  async getBackup(id: string) {
    const backup = await prisma.systemBackup.findUnique({
      where: { id },
    });

    if (!backup) return null;

    return {
      ...backup,
      size: Number(backup.size),
      sizeFormatted: this.formatBytes(Number(backup.size)),
    };
  }

  /**
   * Delete backup
   */
  async deleteBackup(id: string): Promise<boolean> {
    const backup = await prisma.systemBackup.findUnique({
      where: { id },
    });

    if (!backup) return false;

    // Delete file
    try {
      await fs.rm(backup.filepath, { force: true });
    } catch (e) {
      console.error('Error deleting backup file:', e);
    }

    // Delete record
    await prisma.systemBackup.delete({
      where: { id },
    });

    return true;
  }

  /**
   * Get backup file path for download
   */
  async getBackupFilePath(id: string): Promise<string | null> {
    const backup = await prisma.systemBackup.findUnique({
      where: { id },
    });

    if (!backup || backup.status !== 'UPLOADED') return null;

    // SECURITY: Re-validate path from database before returning
    if (!validatePath(backup.filepath, [BACKUP_DIR])) {
      console.error(`[SECURITY] Invalid backup filepath in database: ${backup.filepath}`);
      return null;
    }

    try {
      await fs.access(backup.filepath);
      return backup.filepath;
    } catch (e) {
      return null;
    }
  }

  /**
   * Cleanup old backups based on retention policy
   */
  async cleanupOldBackups(retentionDays: number = 30): Promise<number> {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);

    const oldBackups = await prisma.systemBackup.findMany({
      where: {
        createdAt: { lt: cutoffDate },
        status: 'UPLOADED',
      },
    });

    let deleted = 0;
    for (const backup of oldBackups) {
      try {
        await fs.rm(backup.filepath, { force: true });
        await prisma.systemBackup.delete({ where: { id: backup.id } });
        deleted++;
      } catch (e) {
        console.error(`Error deleting old backup ${backup.id}:`, e);
      }
    }

    return deleted;
  }
}

export const systemBackupService = new SystemBackupService();
